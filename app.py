import streamlit as st
import pandas as pd
import joblib
import numpy as np

# –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
from pathlib import Path
BASE_DIR = Path(__file__).resolve().parent
MODEL_PATH = BASE_DIR / "models" / "soc_model_10f.pkl"
FEATURE_LIST_PATH = BASE_DIR / "models" / "feature_list_10.txt"



# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Ñ–∏—á 
with open(FEATURE_LIST_PATH, "r", encoding="utf-8") as f:
    feature_list = [col.strip() for col in f.read().split(",")]

# –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏—á–µ–π —á–µ—Ä–µ–∑ —Å–ª–æ–≤–∞—Ä—å
feature_names_map = {
    "Packet Length Std": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –ø–∞–∫–µ—Ç–æ–≤",
    "Packet Length Variance": "–î–∏—Å–ø–µ—Ä—Å–∏—è –¥–ª–∏–Ω—ã –ø–∞–∫–µ—Ç–æ–≤",
    "Avg Bwd Segment Size": "–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞ (Bwd)",
    "Max Packet Length": "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–∞–∫–µ—Ç–∞",
    "Bwd Packet Length Max": "–ú–∞–∫—Å. –¥–ª–∏–Ω–∞ –ø–∞–∫–µ—Ç–∞ (Bwd)",
    "Bwd Packet Length Std": "–°—Ç. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –ø–∞–∫–µ—Ç–∞ (Bwd)",
    "Average Packet Size": "–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞",
    "Total Length of Bwd Packets": "–°—É–º–º–∞—Ä–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–∞–∫–µ—Ç–æ–≤ (Bwd)",
    "Total Length of Fwd Packets": "–°—É–º–º–∞—Ä–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–∞–∫–µ—Ç–æ–≤ (Fwd)",
    "Subflow Bwd Bytes": "–ë–∞–π—Ç –≤ –ø–æ–¥–ø–æ—Ç–æ–∫–µ (Bwd)"
}

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∏—á–µ–π
model = joblib.load(MODEL_PATH)
model_classes = list(model.classes_)  # –ö–ª–∞—Å—Å—ã, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å

st.title("üîç SOC –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞—Ñ–∏–∫–∞")
st.write("–í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é, –∑–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞.")

# –î–µ–ª–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
example_normal = {f: 0.0 for f in feature_list}
example_attack = {
    "Packet Length Std": 0.5,
    "Packet Length Variance": 1.2,
    "Avg Bwd Segment Size": 300.0,
    "Max Packet Length": 1500,
    "Bwd Packet Length Max": 1200,
    "Bwd Packet Length Std": 200.0,
    "Average Packet Size": 1000.0,
    "Total Length of Bwd Packets": 5000,
    "Total Length of Fwd Packets": 7000,
    "Subflow Bwd Bytes": 4500,
}

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
def predict_and_show(input_df):
    pred = model.predict(input_df)[0]
    proba = model.predict_proba(input_df)[0]

    if "BENIGN" in model_classes:
        benign_index = model_classes.index("BENIGN")
        attack_proba = 1 - proba[benign_index]
    else:
        # –ë–∏–Ω–∞—Ä–Ω–∞—è –º–æ–¥–µ–ª—å
        attack_proba = proba[1] if len(model_classes) == 2 else None

    if pred != "BENIGN" and pred != 0:
        if attack_proba is not None:
            st.error(f"‚ö† –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ê—Ç–∞–∫–∞: **{pred}** (–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å {attack_proba*100:.2f}%)")
        else:
            st.error(f"‚ö† –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ê—Ç–∞–∫–∞: **{pred}**")
    else:
        if attack_proba is not None:
            st.success(f"‚úÖ –¢—Ä–∞—Ñ–∏–∫ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π (–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å {proba[benign_index]*100:.2f}%)")
        else:
            st.success(f"‚úÖ –¢—Ä–∞—Ñ–∏–∫ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π")

# –í—ã–±–æ—Ä –≤–≤–æ–¥–∞
mode = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –≤–≤–æ–¥–∞", ["–í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é", "–ó–∞–≥—Ä—É–∑–∏—Ç—å CSV", "–ü—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞"])

if mode == "–í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é":
    input_data = {}
    cols = st.columns(2)
    for i, feature in enumerate(feature_list):
        col = cols[i % 2]
        label = feature_names_map.get(feature, feature)
        input_data[feature] = col.number_input(label, value=0.0)

    if st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"):
        input_df = pd.DataFrame([input_data])
        predict_and_show(input_df)

elif mode == "–ó–∞–≥—Ä—É–∑–∏—Ç—å CSV":
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª", type=["csv"])
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        df.columns = df.columns.str.strip()

        missing = [f for f in feature_list if f not in df.columns]
        if missing:
            st.error(f"–í —Ñ–∞–π–ª–µ –Ω–µ—Ç –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {missing}")
        else:
            df = df[feature_list].apply(pd.to_numeric, errors="coerce").fillna(0)
            if st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ñ–∞–π–ª–∞"):
                preds = model.predict(df)
                probs = model.predict_proba(df)
                
                if "BENIGN" in model_classes:
                    benign_index = model_classes.index("BENIGN")
                    attack_probs = 1 - probs[:, benign_index]
                else:
                    attack_probs = probs[:, 1] if len(model_classes) == 2 else np.nan

                result_df = df.copy()
                result_df["Prediction"] = preds
                result_df["Attack Probability"] = attack_probs
                st.write(result_df)
                st.download_button(
                    "–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
                    result_df.to_csv(index=False).encode("utf-8"),
                    "predictions.csv",
                    "text/csv"
                )

else:  # –ü—Ä–∏–º–µ—Ä—ã
    col1, col2 = st.columns(2)
    with col1:
        if st.button("–ü—Ä–∏–º–µ—Ä –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞"):
            df_ex = pd.DataFrame([example_normal])
            st.write(df_ex)
            predict_and_show(df_ex)
    with col2:
        if st.button("–ü—Ä–∏–º–µ—Ä –∞—Ç–∞–∫–∏"):
            df_ex = pd.DataFrame([example_attack])
            st.write(df_ex)
            predict_and_show(df_ex)
